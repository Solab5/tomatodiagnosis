{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9a28a5d-a875-410b-a47f-b428ce87bb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Stages a model for use in production.\n",
    "\n",
    "If based on a checkpoint, the model is converted to torchscript, saved locally,\n",
    "and uploaded to W&B.\n",
    "\n",
    "If based on a model that is already converted and uploaded, the model file is downloaded locally.\n",
    "\n",
    "For details on how the W&B artifacts backing the checkpoints and models are handled,\n",
    "see the documenation for stage_model.find_artifact.\n",
    "\"\"\"\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "#from text_recognizer.lit_models import TransformerLitModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4059bb7-7cfa-42f7-a026-548797c0c5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.util import setup_data_and_model_from_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90d440e8-2a8e-46eb-a291-14c67f04efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these names are all set by the pl.loggers.WandbLogger\n",
    "MODEL_CHECKPOINT_TYPE = \"model\"\n",
    "BEST_CHECKPOINT_ALIAS = \"best\"\n",
    "MODEL_CHECKPOINT_PATH = \"model.ckpt\"\n",
    "LOG_DIR = Path(\"training\") / \"logs\"\n",
    "\n",
    "STAGED_MODEL_TYPE = \"prod-ready\"  # we can choose the name of this type, and ideally it's different from checkpoints\n",
    "STAGED_MODEL_FILENAME = \"model.pt\"  # standard nomenclature; pytorch_model.bin is also used\n",
    "\n",
    "PROJECT_ROOT = Path('.').resolve().parents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d389124c-0412-4738-9904-ff1fb000c415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    }
   ],
   "source": [
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb0e00aa-91be-4f63-9b3a-c207bd299465",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_ENTITY = api.default_entity\n",
    "DEFAULT_FROM_PROJECT = \"deepconc\"\n",
    "DEFAULT_TO_PROJECT = \"deepconc\"\n",
    "DEFAULT_STAGED_MODEL_NAME = \"diseaseclassifier\"\n",
    "\n",
    "PROD_STAGING_ROOT = PROJECT_ROOT / \"tomatodiagnosis\"/ \"diseaseclassifier\" / \"artifacts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb09fcf0-f2d2-4929-8f79-95b14983c8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--staged_model_name STAGED_MODEL_NAME]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /storage/cfg/.local/share/jupyter/runtime/kernel-873b12b8-9d10-4862-8d72-c41a92bd955d.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py:3406: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--staged_model_name', type=str, default='my_model')\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dccd040-bfbc-4e7a-b3b4-a335f1fb5a36",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m prod_staging_directory \u001b[38;5;241m=\u001b[39m PROD_STAGING_ROOT \u001b[38;5;241m/\u001b[39m \u001b[43margs\u001b[49m\u001b[38;5;241m.\u001b[39mstaged_model_name\n\u001b[1;32m      2\u001b[0m prod_staging_directory\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m entity \u001b[38;5;241m=\u001b[39m _get_entity_from(args)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "prod_staging_directory = PROD_STAGING_ROOT / args.staged_model_name\n",
    "prod_staging_directory.mkdir(exist_ok=True, parents=True)\n",
    "entity = _get_entity_from(args)\n",
    "# if we're just fetching an already compiled model\n",
    "if args.fetch:\n",
    "     # find it and download it\n",
    "    staged_model = f\"{entity}/{args.from_project}/{args.staged_model_name}:latest\"\n",
    "    artifact = download_artifact(staged_model, prod_staging_directory)\n",
    "    print_info(artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81077e5-f229-41a1-b962-59c6189f9102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# otherwise, we'll need to download the weights, compile the model, and save it\n",
    "with wandb.init(\n",
    "    job_type=\"stage\", project=args.to_project, dir=LOG_DIR\n",
    "):  # log staging to W&B so prod and training are connected\n",
    "    # find the model checkpoint and retrieve its artifact name and an api handle\n",
    "    ckpt_at, ckpt_api = find_artifact(\n",
    "        entity, args.from_project, type=MODEL_CHECKPOINT_TYPE, alias=args.ckpt_alias, run=args.run\n",
    "    )\n",
    "\n",
    "    # get the run that produced that checkpoint\n",
    "    logging_run = get_logging_run(ckpt_api)\n",
    "    print_info(ckpt_api, logging_run)\n",
    "    metadata = get_checkpoint_metadata(logging_run, ckpt_api)\n",
    "\n",
    "    # create an artifact for the staged, deployable model\n",
    "    staged_at = wandb.Artifact(args.staged_model_name, type=STAGED_MODEL_TYPE, metadata=metadata)\n",
    "    with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "        # download the checkpoint to a temporary directory\n",
    "        download_artifact(ckpt_at, tmp_dir)\n",
    "        # reload the model from that checkpoint\n",
    "        model = load_model_from_checkpoint(metadata, directory=tmp_dir)\n",
    "        # save the model to torchscript in the staging directory\n",
    "        save_model_to_torchscript(model, directory=prod_staging_directory)\n",
    "\n",
    "    # upload the staged model so it can be downloaded elsewhere\n",
    "    upload_staged_model(staged_at, from_directory=prod_staging_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35e0455-ace4-46ba-83fc-6f1b2cb55bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    prod_staging_directory = PROD_STAGING_ROOT / args.staged_model_name\n",
    "    prod_staging_directory.mkdir(exist_ok=True, parents=True)\n",
    "    entity = _get_entity_from(args)\n",
    "    # if we're just fetching an already compiled model\n",
    "    if args.fetch:\n",
    "        # find it and download it\n",
    "        staged_model = f\"{entity}/{args.from_project}/{args.staged_model_name}:latest\"\n",
    "        artifact = download_artifact(staged_model, prod_staging_directory)\n",
    "        print_info(artifact)\n",
    "        return  # and we're done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
