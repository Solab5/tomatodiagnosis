{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f452ef0e-5152-4581-8ff1-b0fd24ea4767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torchvision.models as tvmodels\n",
    "import pandas as pd\n",
    "from fastai.vision.all import *\n",
    "\n",
    "import params\n",
    "from utils import t_or_f\n",
    "\n",
    "def download_data():\n",
    "    \"\"\"Grab dataset from artifact\n",
    "    \"\"\"\n",
    "    processed_data_at = wandb.use_artifact(f'{params.PROCESSED_DATA_AT}:latest')\n",
    "    processed_dataset_dir = Path(processed_data_at.download())\n",
    "    return processed_dataset_dir\n",
    "\n",
    "def get_df(processed_dataset_dir, is_test=False):\n",
    "    df = pd.read_csv(processed_dataset_dir / 'data_split.csv')\n",
    "    if not is_test:\n",
    "        df = df[df.Stage != 'test'].reset_index(drop=True)\n",
    "        df['is_valid'] = df.Stage == 'valid'\n",
    "    else:\n",
    "        df = df[df.Stage != 'train'].reset_index(drop=True)\n",
    "        df['is_valid'] = df.Stage == 'valid'\n",
    "        # when passed to datablock, this will return test at index 0 and valid at index 1\n",
    "    \n",
    "    ## Assign paths\n",
    "    df[\"image_fname\"] = [processed_dataset_dir/f'{f}' for f in df.File_Name.values]\n",
    "    return df\n",
    "\n",
    "def get_data(df, bs=64, img_size=(224, 224), augment=True):\n",
    "    block = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                  get_x=ColReader(\"image_fname\"),\n",
    "                  get_y=ColReader(\"Label\"),\n",
    "                  splitter=ColSplitter(),\n",
    "                  item_tfms=Resize(img_size),\n",
    "                  batch_tfms=aug_transforms() if augment else None,\n",
    "                 )\n",
    "    return block.dataloaders(df, bs=bs)\n",
    "\n",
    "def count_by_class(arr, cidxs): \n",
    "    return [(arr == n).sum(axis=(1,2)).numpy() for n in cidxs]\n",
    "\n",
    "def log_hist(c):\n",
    "    _, bins, _ = plt.hist(target_counts[c],  bins=10, alpha=0.5, density=True, label='target')\n",
    "    _ = plt.hist(pred_counts[c], bins=bins, alpha=0.5, density=True, label='pred')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(params.BDD_CLASSES[c])\n",
    "    img_path = f'hist_val_{params.BDD_CLASSES[c]}'\n",
    "    plt.savefig(img_path)\n",
    "    plt.clf()\n",
    "    im = plt.imread(f'{img_path}.png')\n",
    "    wandb.log({img_path: wandb.Image(f'{img_path}.png', caption=img_path)})\n",
    "\n",
    "run = wandb.init(project=params.WANDB_PROJECT, job_type=\"evaluation\", tags=['staging'])\n",
    "\n",
    "artifact = run.use_artifact('solab5/model-registry/Tomato Disease Diagnosis:v0', type='model')\n",
    "\n",
    "artifact_dir = Path(artifact.download())\n",
    "\n",
    "_model_pth = artifact_dir.ls()[0]\n",
    "model_path = _model_pth.parent.absolute()/_model_pth.stem\n",
    "\n",
    "producer_run = artifact.logged_by()\n",
    "wandb.config.update(producer_run.config)\n",
    "config = wandb.config\n",
    "\n",
    "processed_dataset_dir = download_data()\n",
    "test_valid_df = get_df(processed_dataset_dir, is_test=True)\n",
    "test_valid_dls = get_data(test_valid_df, bs=config.batch_size, img_size=config.img_size, augment=config.augment)\n",
    "\n",
    "metrics=[accuracy, error_rate]\n",
    "\n",
    "cbs = [MixedPrecision()] if config.mixed_precision else []\n",
    "\n",
    "learn = vision_learner(test_valid_dls, arch=getattr(tvmodels, config.arch), pretrained=config.pretrained, metrics=metrics)\n",
    "\n",
    "learn.load(model_path);\n",
    "\n",
    "val_metrics = learn.validate(ds_idx=1)\n",
    "test_metrics = learn.validate(ds_idx=0)\n",
    "\n",
    "val_metric_names = ['val_final_loss', 'val_Accuracy', 'val_Error_rate']\n",
    "val_results = {val_metric_names[i] : val_metrics[i] for i in range(len(val_metric_names))}\n",
    "for k,v in val_results.items(): \n",
    "    wandb.summary[k] = v \n",
    "\n",
    "test_metric_names = ['test_final_loss', 'test_Accuracy', 'test_Error_rate']\n",
    "test_results = {test_metric_names[i] : test_metrics[i] for i in range(len(test_metric_names))}\n",
    "for k,v in test_results.items(): \n",
    "    wandb.summary[k] = v\n",
    "\n",
    "val_probs, val_targs = learn.get_preds(ds_idx=1)\n",
    "val_preds = val_probs.argmax(dim=1)\n",
    "class_idxs = params.BDD_CLASSES.keys()\n",
    "\n",
    "val_targs\n",
    "\n",
    "class_idxs\n",
    "\n",
    "def display_diagnostics(learner, ds_idx=1, return_vals=False):\n",
    "    \"\"\"\n",
    "    Display a confusion matrix for the learner.\n",
    "    If `dls` is None it will get the validation set from the Learner\n",
    "    \n",
    "    You can create a test dataloader using the `test_dl()` method like so:\n",
    "    >> dls = ... # You usually create this from the DataBlocks api, in this library it is get_data()\n",
    "    >> tdls = dls.test_dl(test_dataframe, with_labels=True)\n",
    "    \n",
    "    See: https://docs.fast.ai/tutorial.pets.html#adding-a-test-dataloader-for-inference\n",
    "    \n",
    "    \"\"\"\n",
    "    probs, targs = learner.get_preds(ds_idx=ds_idx)\n",
    "    preds = probs.argmax(dim=1)\n",
    "    classes = list(params.BDD_CLASSES.values())\n",
    "    y_true = targs.flatten().numpy()\n",
    "    y_pred = preds.flatten().numpy()\n",
    "    \n",
    "    tdf, pdf = [pd.DataFrame(r).value_counts().to_frame(c) for r,c in zip((y_true, y_pred) , ['y_true', 'y_pred'])]\n",
    "    countdf = tdf.join(pdf, how='outer').reset_index(drop=True).fillna(0).astype(int).rename(index=params.BDD_CLASSES)\n",
    "    countdf.index = list(params.BDD_CLASSES.values())\n",
    "    countdf = countdf/countdf.sum() \n",
    "    display(Markdown('###% Of Pixels In Each Class'))\n",
    "    display(countdf.applymap('{:.1%}'.format))\n",
    "    \n",
    "    \n",
    "    disp = ConfusionMatrixDisplay.from_predictions(y_true=y_true, y_pred=y_pred,\n",
    "                                                   display_labels=countdf.index,\n",
    "                                                   normalize='pred')\n",
    "    fig = disp.ax_.get_figure()\n",
    "    fig.set_figwidth(10)\n",
    "    fig.set_figheight(10) \n",
    "    disp.ax_.set_title('Confusion Matrix (by Pixels)', fontdict={'fontsize': 32, 'fontweight': 'medium'})\n",
    "    fig.show()\n",
    "    fig.autofmt_xdate(rotation=45)\n",
    "\n",
    "    if return_vals: return countdf, disp\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "val_count_df, val_disp = display_diagnostics(learner=learn, ds_idx=1, return_vals=True)\n",
    "\n",
    "wandb.log({'val_confusion_matrix': val_disp.figure_})\n",
    "val_ct_table = wandb.Table(dataframe=val_count_df)\n",
    "wandb.log({'val_count_table': val_ct_table})\n",
    "\n",
    "test_count_df, test_disp = display_diagnostics(learner=learn, ds_idx=0, return_vals=True)\n",
    "wandb.log({'test_confusion_matrix': test_disp.figure_})\n",
    "test_ct_table = wandb.Table(dataframe=test_count_df)\n",
    "wandb.log({'test_count_table': test_ct_table})\n",
    "\n",
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
