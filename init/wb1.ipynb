{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4d035a2-0f58-44c1-b477-2b41a12f6241",
   "metadata": {},
   "source": [
    "# Tomato Disease Diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc278314-228c-44db-a417-ea11ec044dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e7aa82f-345e-443a-9110-9e552320a28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path.BASE_PATH = path = Path(\"/notebooks/tomatodiagnosis/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570827ef-22d6-4c36-b410-aa8063d4d924",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb7bd628-693e-4e3e-9bc2-52338e587f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#12) [Path('Tomato_Yellow_Leaf_Curl_Virus'),Path('healthy'),Path('Late_blight'),Path('Septoria_leaf_spot'),Path('Leaf_Mold'),Path('Spider_mites'),Path('Tomato_mosaic_virus'),Path('models'),Path('.ipynb_checkpoints'),Path('Early_blight')...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea1202a-8b11-40fd-a37a-708857d8276b",
   "metadata": {},
   "source": [
    "We have 10 classes in our dataset, 9 of these are the tomato diseases whereas the 10th class labels the tomato leaves that are healthy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c5e8a5-2c47-44db-998d-2c4be2794417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "subdir_counts = {}\n",
    "for root, dirs, files in os.walk(path):\n",
    "    num_files = len(files)\n",
    "    if root != path and num_files > 0:\n",
    "        subdir = os.path.basename(root)\n",
    "        subdir_counts[subdir] = num_files\n",
    "    \n",
    "for subdir, count in subdir_counts.items():\n",
    "    print(f\"{subdir}: {count} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe28ba3-5a06-4040-8129-61ca1cf5bc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(subdir_counts, orient=\"index\", columns=[\"File Count\"])\n",
    "df.plot(kind=\"bar\")\n",
    "\n",
    "plt.title(\"Image Counts by class\")\n",
    "plt.xlabel(\"Disease\")\n",
    "plt.ylabel(\"Image Count\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3f9974-686a-412e-8a4f-16c7f9be3c27",
   "metadata": {},
   "source": [
    "The count plot above tells us the distribution of the classes i.e (`Diseases`). It is evident that some of the classes in the dataset are not well represented which implies that the model will struggle to learn how to predict "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687e913a-e448-4b0b-ad54-3d3bed8e8c85",
   "metadata": {},
   "source": [
    "More Data for the classes that aren't well represented can be collected to match the well represented class. Another idea could be trying out trying out some statistical technicals like over sampling or undersampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79133e0d-68fc-4fc2-9c2b-8c9ef4349732",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_image_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c6f51f-4766-4d02-9cc2-e410ed446dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = PILImage.create(files[0])\n",
    "print(img.size)\n",
    "img.to_thumb(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ea98bf-6981-4d01-b145-ed99bcfc3ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.parallel import *\n",
    "\n",
    "def f(o): return PILImage.create(o).size\n",
    "sizes = parallel(f, files, n_workers=8)\n",
    "pd.Series(sizes).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b98b45-9797-4710-86d4-1a325eb2b1f3",
   "metadata": {},
   "source": [
    "There is a total of 18,160 images with the same size of 256 x 256 image pixels. This image size is small and this can imply that our model might struggle while predicting new images that are of a larger size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24710c4-ba6e-453c-938c-74a4b328dbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = ImageDataLoaders.from_folder(path, valid_pct=0.2, seed=42,\n",
    "    batch_tfms=aug_transforms(size=128, min_scale=0.75))\n",
    "\n",
    "dls.show_batch(max_n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beffcc5-ee65-44c3-8718-dbf17252a934",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, 'resnet26d', metrics=error_rate, path='.').to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ae4af9-d98f-4e4e-b63d-cb6a41467057",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find(suggest_funcs=(valley, slide))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b69878-828b-428f-ba0c-9f7f5ddc44dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(3, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b2b916-af33-47de-a129-36c570348126",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.01187269376196545"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
